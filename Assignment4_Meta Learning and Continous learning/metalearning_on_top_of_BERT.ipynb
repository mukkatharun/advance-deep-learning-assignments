{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRc1A4LoOT8H0tunj9cGIa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c21493a0f5cb422c8832af844b0e01f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96507753caae4225ab0070e7e8743328",
              "IPY_MODEL_c165190e84a641d68602f29de78d31ef",
              "IPY_MODEL_2bec1b8faee44c06829bf5f82533d4d3"
            ],
            "layout": "IPY_MODEL_2f17761593334f1c917be2d1f504f268"
          }
        },
        "96507753caae4225ab0070e7e8743328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9a0f5e04b444bb083d2789f01432dc4",
            "placeholder": "​",
            "style": "IPY_MODEL_959d39ed3f584a328de20623730d1a16",
            "value": "Downloading: 100%"
          }
        },
        "c165190e84a641d68602f29de78d31ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726d2ff89b0844438c9207b1393e9c67",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e5c5edff2f44839936e3b6f362dcef5",
            "value": 231508
          }
        },
        "2bec1b8faee44c06829bf5f82533d4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6254eb07cc4b8db381c645ac721352",
            "placeholder": "​",
            "style": "IPY_MODEL_2b598a0d304a4819a145da52c33ffa9f",
            "value": " 232k/232k [00:00&lt;00:00, 638kB/s]"
          }
        },
        "2f17761593334f1c917be2d1f504f268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a0f5e04b444bb083d2789f01432dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959d39ed3f584a328de20623730d1a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726d2ff89b0844438c9207b1393e9c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e5c5edff2f44839936e3b6f362dcef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b6254eb07cc4b8db381c645ac721352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b598a0d304a4819a145da52c33ffa9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47698590df094211a00744fe8154fc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc1152bbaa80469b917c9f076d0e157f",
              "IPY_MODEL_014fab07a9f542b8862b177e9520a42a",
              "IPY_MODEL_98140f46af9b41edb08ef7c44f1e5cef"
            ],
            "layout": "IPY_MODEL_738baa05d39043d0b4f63d6dd9456b27"
          }
        },
        "cc1152bbaa80469b917c9f076d0e157f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c4fb7eb691458587f787bbb8bb6348",
            "placeholder": "​",
            "style": "IPY_MODEL_f5b470f9c61c46d6a3625914db66161e",
            "value": "Downloading: 100%"
          }
        },
        "014fab07a9f542b8862b177e9520a42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea79081e1ce4ee0adf70bfa86a9317c",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a114c509fc94b3a98d698bbd0cffdcf",
            "value": 28
          }
        },
        "98140f46af9b41edb08ef7c44f1e5cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a61ee1abee54d9594ab9c0b1b73954f",
            "placeholder": "​",
            "style": "IPY_MODEL_0eb6ecfbdc984e50af837c9c7061d4e7",
            "value": " 28.0/28.0 [00:00&lt;00:00, 224B/s]"
          }
        },
        "738baa05d39043d0b4f63d6dd9456b27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c4fb7eb691458587f787bbb8bb6348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b470f9c61c46d6a3625914db66161e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ea79081e1ce4ee0adf70bfa86a9317c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a114c509fc94b3a98d698bbd0cffdcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a61ee1abee54d9594ab9c0b1b73954f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eb6ecfbdc984e50af837c9c7061d4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a3ef495f29c49beac1920501e56e466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58470597bdf9400482d53f2652aa5243",
              "IPY_MODEL_056c2eb7ff184e78801ef385915a680a",
              "IPY_MODEL_e164cdb15a064808a6c087769cac20c3"
            ],
            "layout": "IPY_MODEL_1785aef4598c4be48498d9204d0d2242"
          }
        },
        "58470597bdf9400482d53f2652aa5243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d7e0fad30a4d6b88996889d519feaa",
            "placeholder": "​",
            "style": "IPY_MODEL_4c9d10f1124e43d7b61518d3442714f0",
            "value": "Downloading: 100%"
          }
        },
        "056c2eb7ff184e78801ef385915a680a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5801280fe3f64765b9406a428c75a2b0",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_479825d836dc459f859b87878640ceaf",
            "value": 570
          }
        },
        "e164cdb15a064808a6c087769cac20c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1388549f1ce4845abdc2ebf605d06dc",
            "placeholder": "​",
            "style": "IPY_MODEL_871481c6b9964aef86f3f1779876adfd",
            "value": " 570/570 [00:00&lt;00:00, 7.71kB/s]"
          }
        },
        "1785aef4598c4be48498d9204d0d2242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d7e0fad30a4d6b88996889d519feaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c9d10f1124e43d7b61518d3442714f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5801280fe3f64765b9406a428c75a2b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "479825d836dc459f859b87878640ceaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1388549f1ce4845abdc2ebf605d06dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871481c6b9964aef86f3f1779876adfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukkatharun/advance-deep-learning-assignments/blob/main/Assignment4_Meta%20Learning%20and%20Continous%20learning/metalearning_on_top_of_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "Wpzuenmh8to7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "plyXkofV6i-3"
      },
      "outputs": [],
      "source": [
        "# Let inspect the data\n",
        "import json\n",
        "from random import shuffle\n",
        "from urllib.request import urlopen\n",
        "from collections import Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = urlopen('https://raw.githubusercontent.com/mailong25/meta-learning-bert/master/dataset.json')\n",
        "reviews = json.loads(response.read())\n",
        "reviews[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pPsgawR6nf1",
        "outputId": "75c81038-9196-4748-bab8-15b158fe3e4b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': \"GOOD LOOKING KICKS IF YOUR KICKIN IT OLD SCHOOL LIKE ME. AND COMFORTABLE. AND RELATIVELY CHEAP. I'LL ALWAYS KEEP A PAIR OF STAN SMITH'S AROUND FOR WEEKENDS\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'},\n",
              " {'text': 'These sunglasses are all right. They were a little crooked, but still cool..',\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'},\n",
              " {'text': \"I don't see the difference between these bodysuits and the more expensive ones. Fits my boy just right\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'},\n",
              " {'text': 'Very nice basic clothing. I think the size is fine. I really like being able to find these shades of green, though I have decided the lighter shade is really a feminine color. This is the only brand that I can find these muted greens',\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'},\n",
              " {'text': 'I love these socks. They fit great (my 15 month old daughter has thick ankles) and she can zoom around on the kitchen floor and not take a nose dive into things. :',\n",
              "  'label': 'positive',\n",
              "  'domain': 'apparel'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mention_domain = [r['domain'] for r in reviews]\n",
        "Counter(mention_domain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYHaR_-_7K_w",
        "outputId": "52a9dad0-75a3-40ef-8aec-0139900e69a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'apparel': 1717,\n",
              "         'baby': 1107,\n",
              "         'beauty': 993,\n",
              "         'books': 921,\n",
              "         'camera_&_photo': 1086,\n",
              "         'cell_phones_&_service': 698,\n",
              "         'dvd': 893,\n",
              "         'electronics': 1277,\n",
              "         'grocery': 1100,\n",
              "         'health_&_personal_care': 1429,\n",
              "         'jewelry_&_watches': 1086,\n",
              "         'kitchen_&_housewares': 1390,\n",
              "         'magazines': 1133,\n",
              "         'music': 1007,\n",
              "         'outdoor_living': 980,\n",
              "         'software': 1029,\n",
              "         'sports_&_outdoors': 1336,\n",
              "         'toys_&_games': 1363,\n",
              "         'video': 1010,\n",
              "         'automotive': 100,\n",
              "         'computer_&_video_games': 100,\n",
              "         'office_products': 100})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let create meta learning tasks\n"
      ],
      "metadata": {
        "id": "EhT70cf48laq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import collections\n",
        "import random\n",
        "import json, pickle\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "LABEL_MAP  = {'positive':0, 'negative':1, 0:'positive', 1:'negative'}\n",
        "\n",
        "class MetaTask(Dataset):\n",
        "    \n",
        "    def __init__(self, examples, num_task, k_support, k_query, tokenizer):\n",
        "        \"\"\"\n",
        "        :param samples: list of samples\n",
        "        :param num_task: number of training tasks.\n",
        "        :param k_support: number of support sample per task\n",
        "        :param k_query: number of query sample per task\n",
        "        \"\"\"\n",
        "        self.examples = examples\n",
        "        random.shuffle(self.examples)\n",
        "        \n",
        "        self.num_task = num_task\n",
        "        self.k_support = k_support\n",
        "        self.k_query = k_query\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = 128\n",
        "        self.create_batch(self.num_task)\n",
        "    \n",
        "    def create_batch(self, num_task):\n",
        "        self.supports = []  # support set\n",
        "        self.queries = []  # query set\n",
        "        \n",
        "        for b in range(num_task):  # for each task\n",
        "            # 1.select domain randomly\n",
        "            domain = random.choice(self.examples)['domain']\n",
        "            domainExamples = [e for e in self.examples if e['domain'] == domain]\n",
        "            \n",
        "            # 1.select k_support + k_query examples from domain randomly\n",
        "            selected_examples = random.sample(domainExamples,self.k_support + self.k_query)\n",
        "            random.shuffle(selected_examples)\n",
        "            exam_train = selected_examples[:self.k_support]\n",
        "            exam_test  = selected_examples[self.k_support:]\n",
        "            \n",
        "            self.supports.append(exam_train)\n",
        "            self.queries.append(exam_test)\n",
        "\n",
        "    def create_feature_set(self,examples):\n",
        "        all_input_ids      = torch.empty(len(examples), self.max_seq_length, dtype = torch.long)\n",
        "        all_attention_mask = torch.empty(len(examples), self.max_seq_length, dtype = torch.long)\n",
        "        all_segment_ids    = torch.empty(len(examples), self.max_seq_length, dtype = torch.long)\n",
        "        all_label_ids      = torch.empty(len(examples), dtype = torch.long)\n",
        "\n",
        "        for id_,example in enumerate(examples):\n",
        "            input_ids = tokenizer.encode(example['text'])\n",
        "            attention_mask = [1] * len(input_ids)\n",
        "            segment_ids    = [0] * len(input_ids)\n",
        "\n",
        "            while len(input_ids) < self.max_seq_length:\n",
        "                input_ids.append(0)\n",
        "                attention_mask.append(0)\n",
        "                segment_ids.append(0)\n",
        "\n",
        "            label_id = LABEL_MAP[example['label']]\n",
        "            all_input_ids[id_] = torch.Tensor(input_ids).to(torch.long)\n",
        "            all_attention_mask[id_] = torch.Tensor(attention_mask).to(torch.long)\n",
        "            all_segment_ids[id_] = torch.Tensor(segment_ids).to(torch.long)\n",
        "            all_label_ids[id_] = torch.Tensor([label_id]).to(torch.long)\n",
        "\n",
        "        tensor_set = TensorDataset(all_input_ids, all_attention_mask, all_segment_ids, all_label_ids)  \n",
        "        return tensor_set\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        support_set = self.create_feature_set(self.supports[index])\n",
        "        query_set   = self.create_feature_set(self.queries[index])\n",
        "        return support_set, query_set\n",
        "\n",
        "    def __len__(self):\n",
        "        # as we have built up to batchsz of sets, you can sample some small batch size of sets.\n",
        "        return self.num_task"
      ],
      "metadata": {
        "id": "uLCnvt9e7XXN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split meta training and meta testing\n"
      ],
      "metadata": {
        "id": "15DuSXmG8h5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_resource_domains = [\"office_products\", \"automotive\", \"computer_&_video_games\"]\n",
        "train_examples = [r for r in reviews if r['domain'] not in low_resource_domains]\n",
        "test_examples = [r for r in reviews if r['domain'] in low_resource_domains]\n",
        "print(len(train_examples), len(test_examples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuxyxCpl8fZA",
        "outputId": "be9e65e7-4a5e-4891-81c5-3881e93d35b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21555 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
        "train = MetaTask(train_examples, num_task = 100, k_support=100, k_query=30, tokenizer = tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "c21493a0f5cb422c8832af844b0e01f2",
            "96507753caae4225ab0070e7e8743328",
            "c165190e84a641d68602f29de78d31ef",
            "2bec1b8faee44c06829bf5f82533d4d3",
            "2f17761593334f1c917be2d1f504f268",
            "b9a0f5e04b444bb083d2789f01432dc4",
            "959d39ed3f584a328de20623730d1a16",
            "726d2ff89b0844438c9207b1393e9c67",
            "1e5c5edff2f44839936e3b6f362dcef5",
            "6b6254eb07cc4b8db381c645ac721352",
            "2b598a0d304a4819a145da52c33ffa9f",
            "47698590df094211a00744fe8154fc56",
            "cc1152bbaa80469b917c9f076d0e157f",
            "014fab07a9f542b8862b177e9520a42a",
            "98140f46af9b41edb08ef7c44f1e5cef",
            "738baa05d39043d0b4f63d6dd9456b27",
            "64c4fb7eb691458587f787bbb8bb6348",
            "f5b470f9c61c46d6a3625914db66161e",
            "4ea79081e1ce4ee0adf70bfa86a9317c",
            "1a114c509fc94b3a98d698bbd0cffdcf",
            "7a61ee1abee54d9594ab9c0b1b73954f",
            "0eb6ecfbdc984e50af837c9c7061d4e7",
            "9a3ef495f29c49beac1920501e56e466",
            "58470597bdf9400482d53f2652aa5243",
            "056c2eb7ff184e78801ef385915a680a",
            "e164cdb15a064808a6c087769cac20c3",
            "1785aef4598c4be48498d9204d0d2242",
            "45d7e0fad30a4d6b88996889d519feaa",
            "4c9d10f1124e43d7b61518d3442714f0",
            "5801280fe3f64765b9406a428c75a2b0",
            "479825d836dc459f859b87878640ceaf",
            "f1388549f1ce4845abdc2ebf605d06dc",
            "871481c6b9964aef86f3f1779876adfd"
          ]
        },
        "id": "mfsC6FEX8hg8",
        "outputId": "bbfc3468-0b2b-420a-bd2a-4faf921f3aaa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c21493a0f5cb422c8832af844b0e01f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47698590df094211a00744fe8154fc56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a3ef495f29c49beac1920501e56e466"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Take a glance at the first two samples from support set of 1st meta-task\n",
        "train.supports[0][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmGECJRs8oZN",
        "outputId": "450067a3-c1fe-46bf-87ad-13aca8936ac3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'Ordered 2 cables from DLN. They shipped quickly, keep me updated and the cables arrived well packaged. They are good quality and work well. I like that it charges the phone as you Sync up.Highly recommended - and at such a good price',\n",
              "  'label': 'positive',\n",
              "  'domain': 'cell_phones_&_service'},\n",
              " {'text': \"The silicone protective covering for the Treo was exactly what I wanted and just what I expected it to be. It fits my Treo 650 perfectly and I couldn't be happier. I am going to buy another in a different color\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'cell_phones_&_service'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv-2-wKT8358",
        "outputId": "327909aa-47a2-4911-ecc5-594ac1e40316"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataset.TensorDataset at 0x7ff5e8406a90>,\n",
              " <torch.utils.data.dataset.TensorDataset at 0x7ff5e835a310>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let take a look at the first two samples from support set\n",
        "train[0][0][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85ajHvlz80Is",
        "outputId": "0b1b344f-0c7e-4674-9de5-b85d11932366"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  101,  3641,  1016, 15196,  2013, 21469,  2078,  1012,  2027, 12057,\n",
              "           2855,  1010,  2562,  2033,  7172,  1998,  1996, 15196,  3369,  2092,\n",
              "          21972,  1012,  2027,  2024,  2204,  3737,  1998,  2147,  2092,  1012,\n",
              "           1045,  2066,  2008,  2009,  5571,  1996,  3042,  2004,  2017, 26351,\n",
              "           2039,  1012,  3811,  6749,  1011,  1998,  2012,  2107,  1037,  2204,\n",
              "           3976,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [  101,  1996, 13773,  2063,  9474,  5266,  2005,  1996, 29461,  2080,\n",
              "           2001,  3599,  2054,  1045,  2359,  1998,  2074,  2054,  1045,  3517,\n",
              "           2009,  2000,  2022,  1012,  2009, 16142,  2026, 29461,  2080, 13757,\n",
              "           6669,  1998,  1045,  2481,  1005,  1056,  2022, 19366,  1012,  1045,\n",
              "           2572,  2183,  2000,  4965,  2178,  1999,  1037,  2367,  3609,   102,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0]]),\n",
              " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training meta\n"
      ],
      "metadata": {
        "id": "hJNUMv0b884p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.CRITICAL)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "def random_seed(value):\n",
        "    torch.backends.cudnn.deterministic=True\n",
        "    torch.manual_seed(value)\n",
        "    torch.cuda.manual_seed(value)\n",
        "    np.random.seed(value)\n",
        "    random.seed(value)\n",
        "\n",
        "def create_batch_of_tasks(taskset, is_shuffle = True, batch_size = 4):\n",
        "    idxs = list(range(0,len(taskset)))\n",
        "    if is_shuffle:\n",
        "        random.shuffle(idxs)\n",
        "    for i in range(0,len(idxs), batch_size):\n",
        "        yield [taskset[idxs[i]] for i in range(i, min(i + batch_size,len(taskset)))]\n",
        "\n",
        "class TrainingArgs:\n",
        "    def __init__(self):\n",
        "        self.num_labels = 2\n",
        "        self.meta_epoch= 5\n",
        "        self.k_spt=80\n",
        "        self.k_qry=20\n",
        "        self.outer_batch_size = 2\n",
        "        self.inner_batch_size = 12\n",
        "        self.outer_update_lr = 5e-5\n",
        "        self.inner_update_lr = 5e-5\n",
        "        self.inner_update_step = 10\n",
        "        self.inner_update_step_eval = 40\n",
        "        self.bert_model = 'bert-base-uncased'\n",
        "        self.num_task_train = 10\n",
        "        self.num_task_test = 3\n",
        "\n",
        "args = TrainingArgs()"
      ],
      "metadata": {
        "id": "oIjRornp82ng"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Meta Learner"
      ],
      "metadata": {
        "id": "q9iWOsrJ9AN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import BertForSequenceClassification\n",
        "from copy import deepcopy\n",
        "import gc\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Learner(nn.Module):\n",
        "    \"\"\"\n",
        "    Meta Learner\n",
        "    \"\"\"\n",
        "    def __init__(self, args):\n",
        "        \"\"\"\n",
        "        :param args:\n",
        "        \"\"\"\n",
        "        super(Learner, self).__init__()\n",
        "        \n",
        "        self.num_labels = args.num_labels\n",
        "        self.outer_batch_size = args.outer_batch_size\n",
        "        self.inner_batch_size = args.inner_batch_size\n",
        "        self.outer_update_lr  = args.outer_update_lr\n",
        "        self.inner_update_lr  = args.inner_update_lr\n",
        "        self.inner_update_step = args.inner_update_step\n",
        "        self.inner_update_step_eval = args.inner_update_step_eval\n",
        "        self.bert_model = args.bert_model\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        self.model = BertForSequenceClassification.from_pretrained(self.bert_model, num_labels = self.num_labels)\n",
        "        self.outer_optimizer = Adam(self.model.parameters(), lr=self.outer_update_lr)\n",
        "        self.model.train()\n",
        "\n",
        "    def forward(self, batch_tasks, training = True):\n",
        "        \"\"\"\n",
        "        batch = [(support TensorDataset, query TensorDataset),\n",
        "                 (support TensorDataset, query TensorDataset),\n",
        "                 (support TensorDataset, query TensorDataset),\n",
        "                 (support TensorDataset, query TensorDataset)]\n",
        "        \n",
        "        # support = TensorDataset(all_input_ids, all_attention_mask, all_segment_ids, all_label_ids)\n",
        "        \"\"\"\n",
        "        task_accs = []\n",
        "        sum_gradients = []\n",
        "        num_task = len(batch_tasks)\n",
        "        num_inner_update_step = self.inner_update_step if training else self.inner_update_step_eval\n",
        "\n",
        "        for task_id, task in enumerate(batch_tasks):\n",
        "            support = task[0]\n",
        "            query   = task[1]\n",
        "            \n",
        "            fast_model = deepcopy(self.model)\n",
        "            fast_model.to(self.device)\n",
        "            support_dataloader = DataLoader(support, sampler=RandomSampler(support),\n",
        "                                            batch_size=self.inner_batch_size)\n",
        "            \n",
        "            inner_optimizer = Adam(fast_model.parameters(), lr=self.inner_update_lr)\n",
        "            fast_model.train()\n",
        "            \n",
        "            print('----Task',task_id, '----')\n",
        "            for i in range(0,num_inner_update_step):\n",
        "                all_loss = []\n",
        "                for inner_step, batch in enumerate(support_dataloader):\n",
        "                    \n",
        "                    batch = tuple(t.to(self.device) for t in batch)\n",
        "                    input_ids, attention_mask, segment_ids, label_id = batch\n",
        "                    outputs = fast_model(input_ids, attention_mask, segment_ids, labels = label_id)\n",
        "                    \n",
        "                    loss = outputs[0]              \n",
        "                    loss.backward()\n",
        "                    inner_optimizer.step()\n",
        "                    inner_optimizer.zero_grad()\n",
        "                    \n",
        "                    all_loss.append(loss.item())\n",
        "                \n",
        "                if i % 4 == 0:\n",
        "                    print(\"Inner Loss: \", np.mean(all_loss))\n",
        "            \n",
        "            fast_model.to(torch.device('cpu'))\n",
        "            \n",
        "            if training:\n",
        "                meta_weights = list(self.model.parameters())\n",
        "                fast_weights = list(fast_model.parameters())\n",
        "\n",
        "                gradients = []\n",
        "                for i, (meta_params, fast_params) in enumerate(zip(meta_weights, fast_weights)):\n",
        "                    gradient = meta_params - fast_params\n",
        "                    if task_id == 0:\n",
        "                        sum_gradients.append(gradient)\n",
        "                    else:\n",
        "                        sum_gradients[i] += gradient\n",
        "\n",
        "            fast_model.to(self.device)\n",
        "            fast_model.eval()\n",
        "            with torch.no_grad():\n",
        "                query_dataloader = DataLoader(query, sampler=None, batch_size=len(query))\n",
        "                query_batch = iter(query_dataloader).next()\n",
        "                query_batch = tuple(t.to(self.device) for t in query_batch)\n",
        "                q_input_ids, q_attention_mask, q_segment_ids, q_label_id = query_batch\n",
        "                q_outputs = fast_model(q_input_ids, q_attention_mask, q_segment_ids, labels = q_label_id)\n",
        "\n",
        "                q_logits = F.softmax(q_outputs[1],dim=1)\n",
        "                pre_label_id = torch.argmax(q_logits,dim=1)\n",
        "                pre_label_id = pre_label_id.detach().cpu().numpy().tolist()\n",
        "                q_label_id = q_label_id.detach().cpu().numpy().tolist()\n",
        "\n",
        "                acc = accuracy_score(pre_label_id,q_label_id)\n",
        "                task_accs.append(acc)\n",
        "            \n",
        "            fast_model.to(torch.device('cpu'))\n",
        "            del fast_model, inner_optimizer\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        if training:\n",
        "            # Average gradient across tasks\n",
        "            for i in range(0,len(sum_gradients)):\n",
        "                sum_gradients[i] = sum_gradients[i] / float(num_task)\n",
        "\n",
        "            #Assign gradient for original model, then using optimizer to update its weights\n",
        "            for i, params in enumerate(self.model.parameters()):\n",
        "                params.grad = sum_gradients[i]\n",
        "\n",
        "            self.outer_optimizer.step()\n",
        "            self.outer_optimizer.zero_grad()\n",
        "            \n",
        "            del sum_gradients\n",
        "            gc.collect()\n",
        "        \n",
        "        return np.mean(task_accs)"
      ],
      "metadata": {
        "id": "qJPhQHzo87Pu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner = Learner(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5cUN5r49CD-",
        "outputId": "6b3ee2e5-0469-4134-b593-0fb26c2d6af8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed(123)\n",
        "test = MetaTask(test_examples, num_task = 3, k_support=80, k_query=20, tokenizer = tokenizer)\n",
        "random_seed(int(time.time() % 10))"
      ],
      "metadata": {
        "id": "_lUvQ7Hx9H3j"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.supports[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Hzf7a_9JF8",
        "outputId": "d2ac043c-9b4b-4a97-ebbf-2ee74e986c62"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'TO REPLACE THE BATTERY YOUR HAVE TO OPEN THE BACK, THAT MEANS YOU HAVE REMOVE IT FROM WHERE ITS STUCK, OPEN THE BACK AND RE-STICK IT AGAIN THUS LOOSING THE STRENGTH OF THE ORIGINAL GLU',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'This is a very good duster I have owned one for 5 years and now I have to replace',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I have had 2 faulty units right out of the box. The first would not hold a charge for more than a couple of days and that did not improve after cycling the battery a number of times. I returned it for a replacement and that 2nd unit never indicated a full charge - even after being on charge for several days. I am moving on to another brand.Don't waste your time and money on these poor quality items\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': '* Reasonably priced* Used it once so far to jump start; worked perfectly* Very well built; feels sturdy(the LED charge indicator is useful)',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I bought a pair of the reflector about a year ago. I love them. I haven't got a ticket since. Now I drive with confidences. I don't get stressed out when I go through a yellow light or see a photo-radar van on the side of the road. They are not going to get me again. The first $100 ticket was the last as far as I am concerned. Trust me don't wait till you get zapped.\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I purchaced this product because its a great idea. The problem is it only runs when the sun is shining on the solar panel. Also there is not enough suction to get the hot air out. Also the product does not sit on the window firmly and can fall off if you open your window.Hopefully they can take this design an improve the suction and maybe add a battery. Similar to the solar lights you put in your driveway',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I have had this horn on my Triumph Bonneville America for about a year. It is extremely loud and attracts alot of attention. It was easy to install and has proved to be very reliable',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I bought one today for my Mazda Tribute because I didn't like the built-in cup holders. It's actually very sturdy and fits very well.\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"Works great! Use it around the house, on computer monitors, TVs, your car's dash, etc.\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Does not work (cool the interior of the vehicle) barely at all, compared to the ads. So false advertising. I purchased 2, and one also broke right away. Very cheaply made product also. Would never purchase again, nor recommend to anyone',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'This product was purchased as a Christmas gift for my father, unfortunately it did not perform for him. I was replacing this with one that he has had for over 10 years and that one still works and outperfomed this brand new model.I am not sure if we just got a defective one but i dont recommend purchasing although i have to say returning to amazon was straightforward they just simply refunded my money, I will inturn buy my dad something else from amazon you just cant beat the service',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'My husband was very happy to receive this gift. He loves the Mothers products',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I bought 3 sets of these blades for my cars. They lasted 2 weeks (at the most) on average in the summer. Bosch or Anco blades usually work for 2 years. It's up to you to decide which blades to buy!Follow-up: I see some people find my review not helpful, you know what: I tried to warn you. Obviously You either have too much money or You're stockholders of RainX. My advice for You: buy garbage, support economy\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'The Meguiars water magnet lives up to its name. It dries great and does not scratch. Make sure to wash the car with a brush before drying to get all the dirt off, simple powerwashing will not remove all dirt. Do not use one of those california water blades, sand and dirt particles get swiped across the side and leave tons of tiny scrathes',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"What is missing is that the product gets free refills from Zymol for life. So, if you use a lot of high-end wax then this will pay for itself in a few years.And, yes, Zymol makes the best wax I've ever used\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I'm writing this reveiw on the company, Discount Ramps, rather than the ramps themselves. They charged my credit card immediately upon ordering, then 6 weeks later when I inquired about where these ramps were, they told me the manufacturer hadn't received the metal to build them yet, and the build time is 4-6 weeks. Just be careful, people\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I bought this cushion hoping it would make sitting at my computer for long hours more pleasant. Unfortunately after about half an hour, the \"memory foam\" gets totally squished down and it\\'s almost useless. Don\\'t try to save money by getting this cheap one - spend the extra money and get one that doesn\\'t suck.',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Dimensions are confusing/inaccurate. Stated height of 11.5 inches is not correct--perhaps this is shipping container. Actual product is about 8.5 inches high, but taking into account the cradle for tire, only raises the vehicle about 6 inches',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I bought two pair in different sizes and one pair was great but the other pair had deteriorated edges that left water in lines from the first use and one lock didn't secure the blade to the arm well. I had to buy a replacement immediately\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'If this gauge cost $20 I would give it a high rating, but even at the discounted $35 price I see for these gauges I think it is bad value, let alone the nearly $50 it cost me!AS mentioned hose is VERY INFLEXIBLE at cool, not just cold temps, general quality of the fittings is very poor for something advertised like this, mine is now leaking badly and I am trying to repair with quality materials, as I still hope to use the gauge part anyway. I would NOT BUY AGAIN',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Loved the price but I never actually received the item. It shipped to the wrong address and I never got it back :-',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Waste of money, lasted ONLY 2 weeks this summer. Garbage. Pay a little more for Bosch or same for Anco',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Absolutely useless. Do not buy this product. You are wasting your money. Learn from me. I wasted on two! They are tiny tiny fans that move hardly any air at all. Also they DO NOT work on tinted windows. Trust me.Save yourself some money and just crack your windows. It works 100% better',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Bought one of these to jump start my 3.6 litre 911. It doesnt have the power to even turn it over once when fully charged. Complete waste of time, maybe it will start a lawn mower.',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'This is bad, very bad. It slips so easy that you cannot get a firm grip on the filter. I would suggest anyone to look elsewhere and get something else that actually works. I really regret getting this',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'The product is not working. The provider is terrible!! You can not reach them via email nor return the product. It is the worst experience in AMAZON!! I wish I knew this provider and read these reviews before I bought it!!!',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I am not trying for a show quality shine, just a nice clean car and drying with spots was always the issue for me outside the $6 wash. I liked this. I washed and watched dry two cars and a motorcycle in just the time it took to wet, wipe with soap, and rinse with the no spot setting. Worked great for the price.',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I hope the person reviewing above is joking because it is not a body hair removal wax, it is for automobiles. The high percentage of white carnuba which is what it is made with provides an intense luster to the car paint',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'My fiancee loves these. They are cute and they keep the car clean, and they match the comfy steering wheel cover',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I use this as an alternate 12V power source to power a 12Vair compressor and it is a great product! It can power aSpot Light(15 watts/12V) for 12 hours. So it doesn't have a problem at all when I blow up tires, floats etc.\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"Lasts only 2 weeks! Try them if you don't believe me\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"Advertised as easy to install. Just hook up the existing horns wires and you have it......WRONG. If your existing relay is not compatible with the horn you get to purchase a new relay and rewire a whole new horn button somewhere on the vehicle. They also don't tell you it is NOT COMPATIBLE WITH MOTORCYCLE RELAYS. If you get past all of this it does have a great sound\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Have always used the regular California Duster. Time to replace the one I have had for years. Thought I would try the Extra Large duster. This has twice the dusting surface, it is faster and does the same great job. I have a black Town and Country which shows dust! This does a great job in just a few minutes. A great product',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"My car was stolen with device engaged. It was stolen while my wife and I were both at home. We did not hear a single thing. Their 'guarantee' by the way is a complete farse. Wow, they'll cover the deductable... but only on a comprehensive coverage policy. If you are wanting to keep your car safe, DO NOT BUY THIS PRODUCT!!\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"They broke the first time that I used them. The locking mechanism is cheap and slides out of its intended slot. Don't waste your money on this item\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I installed this cover and took pictures from various distance and angel. I could read all numbers clearly. They claim that it will work with actual traffic camera. I have no way to test that',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'The reflector cover works great! It has consistently kept those tickets out of my mailbox. Its simplicity and ease of use is what made me interested in it in the first place, and now I can be sure that it is a 100% effective for all those red light cameras. I would seriously advice all of you to get this product...it definitely does justice to the unfairness of costly traffic tickets (most likely not even your fault!) Excellent Product!',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Works just as I anticipated..great Product ..Very simple way to Put onto your Licence Plate and definetly worth the Buy. It doesnt get no bette',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"What a bad product! They didn't last two weeks before they began to smear my windshield\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'What can I say? Mothers makes great stuff for auto care and this is one of them. Just make sure you read the instructions and do it right. Also, this is not going to raise any death from its grave, it the wheel is pretty busted it may just not have hope',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"Perhaps Black and Decker got a lot of complaints about an earlier edition of this item-- but I should note first that the one I received today has nice, heavy metal clamps.Haven't used it yet but I'm confident it will work well. I'm very impressed by the apparent high quality of construction and fit and finish, as well as design.Frankly, I think it would be a good value at the $49.99 Amazon lists as the retail price-- but of course Amazon's price with free shipping is that much better\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"Ok It's so obviously obstructing the view of your license plate. I thought it would only blur it from the high distant angles of the cameras but it blurs it from almost every angle besides directly behind it (and even then the edges are blurry). Check the laws in your local state. I'm pretty sure this thing is very illegal!!! I had to trash mine. Thanks for taking my money\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I had a previous non-brand name digital tire gauge and it worked great but eventually died. I bought this one thinking it would be better. The first time I used it I couldn't get a good connection at all and it kept giving me multiple readings. It also does not seem to keep the number on the display after the reading. It would disappear before i could read it fully.\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'A wonderful kit to have in case of an emergency situation. All that it lacks it a cellphone',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'IMPOSSIBLE TO RATE PRODUCT AS AMAZON SHIPPED BRAKE CLEANER INSTEAD OF POLISH. RETURN OF INEXPENSIVE ITEMS NOT WORTH THE TIME IT TAKES. CONSIDER NOT USING AMAZON FOR SMALL PURCHASES UNTIL RETURN SYSTEM IS UPGRADED',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Has everything and more inside.Great price concidering how much you get.Literally has like $100 of stuff in it',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Installed this on my 2006 Civic EX Sedan to replace the pathetic (meep...meep!) sounding factory horn. The factory horn made me shrink in embarassment everytime I used it. Well, no more - this Bad Boy made the receiving end to shrink now...lol.',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'This duster is heavy duty, does a great job and is much bigger that I thought it would be. Overall I am very happy with this item. If you need a car duster this one is a home run',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I have not used this product. Our local news did a test on it. They found that in 2 vehicles (exactly the same) that this device only lowered the temp 1 degree. Again, I have not used it, I am just throwing the test I saw out there. Their call sign is WCPO, so look it up from there (not allowed to include link)',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"Didn't realize how easy and effective it is until now. I can clean a room in a couple of minutes. Definitely worth buying\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'These are great blades, installation is very straight forward. The only gripe I have about these blades is the contact of the blade and the windshield at the extreme right where it ceases to touch my windshield which is about a 1/2\", but the odd thing is that the tip does touch my windshield on the up stroke. But it is so minor that it would not affect the rating at all since these blades has to fit onto so many different cars. I guess there are no replacement for factory blades',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Worth the price as my window is ALWAYS clean. Just for a comparison I leave a new but lesser quality wiper on the passenger side. The difference is incredible.',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'The powerball products work well, if you have wheels and other billet goodies this will become your best buddy',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"This is a much nicer seat cover than I imagined it would be (especially for the cost). The only complaint I have is that with it in place, I can't extend my head rest (I'm tall), but other than that, it's very comfortable, and protects the car seat under it very well. I wear suspenders, and without something to protect the seat, the car seat gets cut by the buckles\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"Simplifies car washing, as soap and water are contained in the easy to use sprayer. The best thing is the finish...eliminates the need for drying with chamois, etc. and leaves a streak-free spotless finish, especially on windows. I'm happy with it\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I recently bought a pair of the reflector cover from photoblocker store on Amazon. After I put it on my plates I have been through several red light intersections in the evenings on numerous occasions and to date I have yet to receive a fine, I believe the reflector cover has already paid for itself.',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I just bought a new white convertible and this product is the greatest for quickly removing dust and light dirt. I am using it daily as it is so easy and quick. Car is spotless after 3 weeks of heavy driving, and I haven't needed to use my free car wash from the dealer\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'As other reviewers mentioned, the display does not update when using the bleed valve and you have to wait at least 10 seconds between readings. It may be accurate, but dropping overpressure tires to a desired level ends up being a several-minute guessing and waiting game. Calling it a \"racing\" gauge is ridiculous',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"Listen if you truly want an ionizer that dramaticaly changes the air. I strongly advise people to purchase one by Flair. This home unit retails for $300. Need results, that's what a real one costs\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"i wouldn't recommend this product. The positive terminal clamp broke in half the first time i used it... I, as I was stranded, rigged up a method to make contact with the terminal w/ the remaining half of the clamp. Then the charger (which was charged fully the previous night) didn't provide enough power to actually turn the engine over. I will be returning to the store tonight, returning this item, and purchasing a different charger\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'This duster is fabulous. Dusting will never be fun, but with this tool it almost IS! As a computer teacher I purchased two. The students even ASKED if they could dust with it. They did a great job on the computer screens, tables, and shelves',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'The cushion was designed for what I needed due to an injury, but the curve of the cushion, the pressure points, and the density of the cushion are wrong. I guess you get what you pay for. I have found a similar cushion that works very well',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I cannot believe they put this on the market. Once it gets wet, there isn\\'t much you can do about wringing it out. It\\'s title is true - it is a water magnet. The problem is it just won\\'t let the water go. This towel is horrible. I suggest using the 3-pack microfiber Meguiar\\'s towels sold by Amazon as well under the subject \"Meguiar\\'s X2020 Supreme Shine Microfiber - Pack of 3\"',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"Several people here have mentioned that the clips are made of cheap plastic. I'm happy to report that mine received march 2 2007 has all-metal clips that seem to be quite sturdy! They have definately updated the design\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Many years back I worked retail and the shelves in my store were all black and our district office always sent us these dusters to clean the shelves with. So, now many years down the road we refurnished our living room w/ black furniture and the first thing I did was go out and get one of these. It is the best thing ever for dusting! It leaves absolutely NO lint behind and works like a charm!',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'My last 5 cars had leather seats. My new Town and Country has fabric seats. My wife insisted I get leather. The Wagen Tech IN-2248 Looks Right, Fits right, feels right. I liked it so well I bought another for my side of the T&C THE right product at the right peiceJerell Sorensen',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"This bag was junk on a 2001 4Runner. The poor fit made it hard to secure and even more difficult to load and unload. I realize it isn't made for all vehicles but I purchased mine only after speaking with Lund, who confirmed the bag would work on my vehicle. Spend the extra money and buy a hard shell unit with adjustable hardware. Great service from Amazon, terrible service from Lund\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"The desert gets really dusty, so having this product to swipe over my car (especially windows) helps me save money on car washes. I wish the package had included a bigger cover to store the brush in. It's awkward putting it back into the same cover it came in, once you start accumulating dirt.\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I own both the original unbreakable autolock (with the flat key) and the autolock pro (with the round key). The original autolock never failed to open after 10+ years of use on two cars. The autolock pro failed to open after about two years of light use. This is not a key problem, because I could not open it with two original keys. I eventually wiggled the lock a lot to open it. I recommend that you stick with the original autolock if you wish to use this kind of security device',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'If were a celebrity I would endorse it on TV.It sweeps my car, hood, windows, roof, trunk lid and headlights beautifully!The scraper is fierce and lets ice on the window know whox1as boss! ME thatx1as who, with my long reach, red handled, Blizzard model 3512 snowbrush and scraper. Thanks Hoppy!',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I got this item for my coffee-loving truck driver husband. When we took it out of the box, we saw the obvious problem: the \"mug\" is tiny! Only a bit larger than an espresso cup. To add insult to injury, it took way too long to brew for such a small cup. Now it\\'s back in the box collecting dust and we\\'re sorry we wasted our hard-earned money',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I bought one today for my Mazda Tribute because I didn't like the built-in cup holders. It's actually very sturdy and fits very well.\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Very nice product. Holds lots of things - especially able to put full size pieces of paper in a zippered compartment, which is very useful for me.',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'I use this system on the outside of the windows of our home and love it. I picked up a long handled sheepskin window washing tool and love the whole system. Must do the windows when the sun is NOT on them. It has worked great now for two years. Inside of windows shine if you use a window cleaner and newspapers. I thought the newspapers would not absorb the cleaner--but they work great. Hope you find this as useful as I have. Bluekitt',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'The Super Duster has been very efficient in removing dust off my new 2005 Camry XLE and keeping her shiny between washes. Along with trimming car wash expenses, the full knitting minimizes twists of the wrist inherent with one-sided dusters to keep upright.I recommend this product most highly.Paul Everett VinsonSan Antonio, T',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Very thorough kit - seems to be a very good value for everything included. My husband really liked it',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"It's a pain because to save time you need to install it permanently to make it worth it. Then you can never use that window for anything else. It's a pain because it will NOT work on tinted windows.Run\",\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'},\n",
              " {'text': \"I like to think of my self as a responsible driver but when I get a ticket for going over 10mph I get really ticked off. I searched trough the internet trying to find a solution for these ridicules tickets and I found the reflector cover. This stuff is amazing, I have seen a flash go off while I pass trough speed camera. It's been almost 2 months and I still didn't get any ticket. I think everyone should protect themselves with the reflector cover because the cameras are there to collect revenue instead of protecting the public\",\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'Great Product!..My wife gave it to me as a birthday present and I thought what a cheap gift..But who would have ever thought this would actually save me a year of tickets',\n",
              "  'label': 'positive',\n",
              "  'domain': 'automotive'},\n",
              " {'text': 'This is THE worst smelling \"freshener\" I have ever used. Its just a terrible smell. Like the other reviewer said, its very chemical in nature. I sprayed som in my living room to see what it was like and.....WOW. I opened the windoes pretty quick, I could not imagine this in a hot car. I picked it up for 1.50 at a BigLots and I feel ripped off.Dont buy it',\n",
              "  'label': 'negative',\n",
              "  'domain': 'automotive'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start training"
      ],
      "metadata": {
        "id": "mL7zr5cn9Mji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_step = 0\n",
        "\n",
        "for epoch in range(args.meta_epoch):\n",
        "    \n",
        "    train = MetaTask(train_examples, num_task = 50, k_support=80, k_query=20, tokenizer = tokenizer)\n",
        "    db = create_batch_of_tasks(train, is_shuffle = True, batch_size = args.outer_batch_size)\n",
        "\n",
        "    for step, task_batch in enumerate(db):\n",
        "        \n",
        "        f = open('log.txt', 'a')\n",
        "        \n",
        "        acc = learner(task_batch)\n",
        "        \n",
        "        print('Step:', step, '\\ttraining Acc:', acc)\n",
        "        f.write(str(acc) + '\\n')\n",
        "        \n",
        "        if global_step % 20 == 0:\n",
        "            random_seed(123)\n",
        "            print(\"\\n-----------------Testing Mode-----------------\\n\")\n",
        "            db_test = create_batch_of_tasks(test, is_shuffle = False, batch_size = 1)\n",
        "            acc_all_test = []\n",
        "\n",
        "            for test_batch in db_test:\n",
        "                acc = learner(test_batch, training = False)\n",
        "                acc_all_test.append(acc)\n",
        "\n",
        "            print('Step:', step, 'Test F1:', np.mean(acc_all_test))\n",
        "            f.write('Test' + str(np.mean(acc_all_test)) + '\\n')\n",
        "            \n",
        "            random_seed(int(time.time() % 10))\n",
        "        \n",
        "        global_step += 1\n",
        "        f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4U_bodS9Klx",
        "outputId": "7beee66c-7792-4602-f14b-5692a34addd8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----Task 0 ----\n",
            "Inner Loss:  0.6705008830342974\n",
            "Inner Loss:  0.026188497032438005\n",
            "Inner Loss:  0.0035540771537593435\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.694626910345895\n",
            "Inner Loss:  0.03510607087186405\n",
            "Inner Loss:  0.004872651238526616\n",
            "Step: 0 \ttraining Acc: 0.8\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.603544111762728\n",
            "Inner Loss:  0.018962965479918888\n",
            "Inner Loss:  0.0038936012757143806\n",
            "Inner Loss:  0.002167785506961601\n",
            "Inner Loss:  0.0016486313959051455\n",
            "Inner Loss:  0.0012128052434750966\n",
            "Inner Loss:  0.0009087345346675388\n",
            "Inner Loss:  0.0007802058992508266\n",
            "Inner Loss:  0.0006276136430512581\n",
            "Inner Loss:  0.000529784314234608\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.7159415994371686\n",
            "Inner Loss:  0.04298292366521699\n",
            "Inner Loss:  0.004384980204382113\n",
            "Inner Loss:  0.002289766595432801\n",
            "Inner Loss:  0.0016442898527852126\n",
            "Inner Loss:  0.0012598024914041162\n",
            "Inner Loss:  0.0009344997982095395\n",
            "Inner Loss:  0.0007940684112587146\n",
            "Inner Loss:  0.0006482180989613491\n",
            "Inner Loss:  0.0005505340938855495\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6022892636912209\n",
            "Inner Loss:  0.03425190491335733\n",
            "Inner Loss:  0.0057746074827654025\n",
            "Inner Loss:  0.002811719397349017\n",
            "Inner Loss:  0.0019789112266153097\n",
            "Inner Loss:  0.00143213350591915\n",
            "Inner Loss:  0.001181550307332405\n",
            "Inner Loss:  0.0009757587519873466\n",
            "Inner Loss:  0.000769285235687026\n",
            "Inner Loss:  0.000664832627600325\n",
            "Step: 0 Test F1: 0.85\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6771899802344186\n",
            "Inner Loss:  0.029447429414306368\n",
            "Inner Loss:  0.0032333415666861193\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5805331170558929\n",
            "Inner Loss:  0.05545907840132713\n",
            "Inner Loss:  0.002734194908823286\n",
            "Step: 1 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5787415078708104\n",
            "Inner Loss:  0.04212656058371067\n",
            "Inner Loss:  0.008698965755424328\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5254598600523812\n",
            "Inner Loss:  0.023445335615958487\n",
            "Inner Loss:  0.0052397506577628\n",
            "Step: 2 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4611985683441162\n",
            "Inner Loss:  0.01357811942164387\n",
            "Inner Loss:  0.0031182554084807634\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5074616244861058\n",
            "Inner Loss:  0.025543191071067537\n",
            "Inner Loss:  0.00656592652999929\n",
            "Step: 3 \ttraining Acc: 0.775\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4518615858895438\n",
            "Inner Loss:  0.08263528746153627\n",
            "Inner Loss:  0.007333634022091117\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.6489857860973903\n",
            "Inner Loss:  0.01857116392680577\n",
            "Inner Loss:  0.003412227611988783\n",
            "Step: 4 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.37406040728092194\n",
            "Inner Loss:  0.008626769496394055\n",
            "Inner Loss:  0.0023121971005041686\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.41172394156455994\n",
            "Inner Loss:  0.01286789242710386\n",
            "Inner Loss:  0.0028394640955541816\n",
            "Step: 5 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.41660964701856884\n",
            "Inner Loss:  0.023097220276083266\n",
            "Inner Loss:  0.003105291198672993\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.36425977306706564\n",
            "Inner Loss:  0.024885177479258606\n",
            "Inner Loss:  0.0032420123129018714\n",
            "Step: 6 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2820380340729441\n",
            "Inner Loss:  0.022973158130688325\n",
            "Inner Loss:  0.0032714164948889186\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3308961774621691\n",
            "Inner Loss:  0.057459574724946706\n",
            "Inner Loss:  0.00393796173323478\n",
            "Step: 7 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.45871684168066296\n",
            "Inner Loss:  0.04503293734576021\n",
            "Inner Loss:  0.00401447673461267\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5198708325624466\n",
            "Inner Loss:  0.059940584003925323\n",
            "Inner Loss:  0.0035755026287266184\n",
            "Step: 8 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.43451195316655294\n",
            "Inner Loss:  0.022312828206590245\n",
            "Inner Loss:  0.005950206657871604\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.23420326358505658\n",
            "Inner Loss:  0.06887235572295529\n",
            "Inner Loss:  0.0039461201855114526\n",
            "Step: 9 \ttraining Acc: 0.85\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2742702913071428\n",
            "Inner Loss:  0.008295974960284573\n",
            "Inner Loss:  0.0023997244757733177\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.594964432397059\n",
            "Inner Loss:  0.07087323814630508\n",
            "Inner Loss:  0.007429370922701699\n",
            "Step: 10 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.39758275875023436\n",
            "Inner Loss:  0.008008429980171579\n",
            "Inner Loss:  0.0019112955279914396\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3503898818578039\n",
            "Inner Loss:  0.013530266870345389\n",
            "Inner Loss:  0.002615444960870913\n",
            "Step: 11 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.38407616849456516\n",
            "Inner Loss:  0.01942156720906496\n",
            "Inner Loss:  0.0027159459090658595\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.27195644431880545\n",
            "Inner Loss:  0.005540836203311171\n",
            "Inner Loss:  0.001514809871358531\n",
            "Step: 12 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.16045595492635453\n",
            "Inner Loss:  0.004499748182882156\n",
            "Inner Loss:  0.11044036853127182\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.23357142029064043\n",
            "Inner Loss:  0.014275230068181242\n",
            "Inner Loss:  0.0022290226271642105\n",
            "Step: 13 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2630255674677236\n",
            "Inner Loss:  0.04277753284467118\n",
            "Inner Loss:  0.0075018445828131265\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5509650664670127\n",
            "Inner Loss:  0.03810430743864605\n",
            "Inner Loss:  0.006080900518489736\n",
            "Step: 14 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.49596872872539927\n",
            "Inner Loss:  0.017749685927161148\n",
            "Inner Loss:  0.0034262403579694884\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.42220118109669\n",
            "Inner Loss:  0.015617662375526769\n",
            "Inner Loss:  0.0033698835011039463\n",
            "Step: 15 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3751979385103498\n",
            "Inner Loss:  0.05819355723048959\n",
            "Inner Loss:  0.0064524986248995575\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3855644778481552\n",
            "Inner Loss:  0.03992511132465942\n",
            "Inner Loss:  0.0028720119236303227\n",
            "Step: 16 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.7760001101664135\n",
            "Inner Loss:  0.1053188783781869\n",
            "Inner Loss:  0.013757634907960892\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5126317292451859\n",
            "Inner Loss:  0.030192102172545025\n",
            "Inner Loss:  0.01907732410888587\n",
            "Step: 17 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.35457035233931883\n",
            "Inner Loss:  0.08214494798864637\n",
            "Inner Loss:  0.008803219667502813\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.452063789258578\n",
            "Inner Loss:  0.02748846635222435\n",
            "Inner Loss:  0.004545808902808598\n",
            "Step: 18 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.28688991761633326\n",
            "Inner Loss:  0.0135676327294537\n",
            "Inner Loss:  0.00258920927132879\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.34251671590443167\n",
            "Inner Loss:  0.09748341276177339\n",
            "Inner Loss:  0.007896141880857093\n",
            "Step: 19 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1383489016443491\n",
            "Inner Loss:  0.006664877790691597\n",
            "Inner Loss:  0.0017074983500476395\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.49303053186408113\n",
            "Inner Loss:  0.034487164446285794\n",
            "Inner Loss:  0.0064405215504978386\n",
            "Step: 20 \ttraining Acc: 0.8999999999999999\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3530548095836171\n",
            "Inner Loss:  0.017611750401556492\n",
            "Inner Loss:  0.003249709228319781\n",
            "Inner Loss:  0.0014970743463241629\n",
            "Inner Loss:  0.0010676634597725102\n",
            "Inner Loss:  0.0008011042456408697\n",
            "Inner Loss:  0.0005912501780715372\n",
            "Inner Loss:  0.0005306947194705052\n",
            "Inner Loss:  0.00042143188849357624\n",
            "Inner Loss:  0.00034248217291730853\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4106736518442631\n",
            "Inner Loss:  0.006941356762711491\n",
            "Inner Loss:  0.0019361302090276564\n",
            "Inner Loss:  0.0011622919368424586\n",
            "Inner Loss:  0.0009717591788752802\n",
            "Inner Loss:  0.0006536711506279451\n",
            "Inner Loss:  0.0004922449173006628\n",
            "Inner Loss:  0.00042713459697552025\n",
            "Inner Loss:  0.0003452855162322521\n",
            "Inner Loss:  0.00029411645456483323\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3151086124458483\n",
            "Inner Loss:  0.020910718544785465\n",
            "Inner Loss:  0.0021119305165484548\n",
            "Inner Loss:  0.0011064910795539618\n",
            "Inner Loss:  0.0007748739777265915\n",
            "Inner Loss:  0.0005897835529010211\n",
            "Inner Loss:  0.0005059832973139626\n",
            "Inner Loss:  0.0004178578092250973\n",
            "Inner Loss:  0.0003308850573375821\n",
            "Inner Loss:  0.0002895160411883678\n",
            "Step: 20 Test F1: 0.9333333333333332\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3901599922350475\n",
            "Inner Loss:  0.05182847939431667\n",
            "Inner Loss:  0.004859572476042169\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.6165264411829412\n",
            "Inner Loss:  0.1178828552365303\n",
            "Inner Loss:  0.021407917674098696\n",
            "Step: 21 \ttraining Acc: 0.85\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.37664531969598364\n",
            "Inner Loss:  0.007171783928892442\n",
            "Inner Loss:  0.002027472314823951\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.415921830705234\n",
            "Inner Loss:  0.015198133486722196\n",
            "Inner Loss:  0.006753480261457818\n",
            "Step: 22 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.23997473643560494\n",
            "Inner Loss:  0.025089803817016736\n",
            "Inner Loss:  0.008101462852209806\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4766927734017372\n",
            "Inner Loss:  0.06305615098348685\n",
            "Inner Loss:  0.039437920919486454\n",
            "Step: 23 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2891412066029651\n",
            "Inner Loss:  0.0054209417929606775\n",
            "Inner Loss:  0.0021037322336009572\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.6050879827567509\n",
            "Inner Loss:  0.09483056249363082\n",
            "Inner Loss:  0.008944706592176641\n",
            "Step: 24 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.44693016207643915\n",
            "Inner Loss:  0.06948357048843588\n",
            "Inner Loss:  0.040188715527100224\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3059147173272712\n",
            "Inner Loss:  0.1299297543508666\n",
            "Inner Loss:  0.05207075338278498\n",
            "Step: 0 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.16761641440513944\n",
            "Inner Loss:  0.008740303505744253\n",
            "Inner Loss:  0.002052636135236493\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5199670234828123\n",
            "Inner Loss:  0.014352750299232346\n",
            "Inner Loss:  0.003957777317347271\n",
            "Step: 1 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.27220115943678785\n",
            "Inner Loss:  0.03788305473114763\n",
            "Inner Loss:  0.004896989491369043\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.47076882268967374\n",
            "Inner Loss:  0.015129187277385167\n",
            "Inner Loss:  0.004081682667934469\n",
            "Step: 2 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6522426352437053\n",
            "Inner Loss:  0.09032367755259786\n",
            "Inner Loss:  0.007892618554511241\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16091601543926767\n",
            "Inner Loss:  0.0028479185088404585\n",
            "Inner Loss:  0.0069251418213493055\n",
            "Step: 3 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5206464108279241\n",
            "Inner Loss:  0.012827108414577586\n",
            "Inner Loss:  0.0044599654086466345\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5031117578702313\n",
            "Inner Loss:  0.13518592129860604\n",
            "Inner Loss:  0.07051646815879005\n",
            "Step: 4 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.32143497180991937\n",
            "Inner Loss:  0.058204242028295994\n",
            "Inner Loss:  0.0037770861028028385\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.34405016426795293\n",
            "Inner Loss:  0.02645596276436533\n",
            "Inner Loss:  0.003681529512895005\n",
            "Step: 5 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.7393668496182987\n",
            "Inner Loss:  0.019380427497838224\n",
            "Inner Loss:  0.003374297171831131\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2816634933863367\n",
            "Inner Loss:  0.00890689090426479\n",
            "Inner Loss:  0.002388782283690359\n",
            "Step: 6 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3257913059288902\n",
            "Inner Loss:  0.00697712620188083\n",
            "Inner Loss:  0.0018583133018442563\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5256189190217161\n",
            "Inner Loss:  0.017324667823101794\n",
            "Inner Loss:  0.0036236406303942204\n",
            "Step: 7 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.31734075490385294\n",
            "Inner Loss:  0.006400390494880932\n",
            "Inner Loss:  0.0013398724342031138\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.43277687127036707\n",
            "Inner Loss:  0.05454830851938043\n",
            "Inner Loss:  0.003863865476367729\n",
            "Step: 8 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2646767683327198\n",
            "Inner Loss:  0.0038952777893947704\n",
            "Inner Loss:  0.001041554837554161\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4793833128974906\n",
            "Inner Loss:  0.018683995785457746\n",
            "Inner Loss:  0.004679598246834108\n",
            "Step: 9 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5169759757284608\n",
            "Inner Loss:  0.012499222664960794\n",
            "Inner Loss:  0.0026006651377039297\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3220083871856332\n",
            "Inner Loss:  0.004671092211667981\n",
            "Inner Loss:  0.0009619224750037704\n",
            "Step: 10 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.39747125030096087\n",
            "Inner Loss:  0.008413683556552445\n",
            "Inner Loss:  0.0025597825712923494\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4412180321690227\n",
            "Inner Loss:  0.019314243458211422\n",
            "Inner Loss:  0.0044152568360524514\n",
            "Step: 11 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.07399572245776653\n",
            "Inner Loss:  0.003003229686458196\n",
            "Inner Loss:  0.0008264343653406416\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.18648815075201647\n",
            "Inner Loss:  0.014491335455594319\n",
            "Inner Loss:  0.002224285330157727\n",
            "Step: 12 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.29856550141370725\n",
            "Inner Loss:  0.00633394721496318\n",
            "Inner Loss:  0.0014936944769163216\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1495699328037777\n",
            "Inner Loss:  0.0017907894050170267\n",
            "Inner Loss:  0.00043873587024531195\n",
            "Step: 13 \ttraining Acc: 0.85\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.37952988741121124\n",
            "Inner Loss:  0.009344284422695637\n",
            "Inner Loss:  0.0018248925750542963\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.41891539256487575\n",
            "Inner Loss:  0.01157588411920837\n",
            "Inner Loss:  0.0018072361791772501\n",
            "Step: 14 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2846739518323115\n",
            "Inner Loss:  0.0062499201324369225\n",
            "Inner Loss:  0.0013431310653686523\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.28591574020018534\n",
            "Inner Loss:  0.006280565168708563\n",
            "Inner Loss:  0.0009434574499859341\n",
            "Step: 15 \ttraining Acc: 0.95\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.28192011446559\n",
            "Inner Loss:  0.005842983456594604\n",
            "Inner Loss:  0.0011941086850129068\n",
            "Inner Loss:  0.0006594361122032362\n",
            "Inner Loss:  0.0005030621042741197\n",
            "Inner Loss:  0.00038974172535485456\n",
            "Inner Loss:  0.00029434981739281544\n",
            "Inner Loss:  0.0002572937768750957\n",
            "Inner Loss:  0.0002126257521532742\n",
            "Inner Loss:  0.00017955627741425166\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.289881317344095\n",
            "Inner Loss:  0.002334350404063506\n",
            "Inner Loss:  0.0008483304159848817\n",
            "Inner Loss:  0.0005399199061295283\n",
            "Inner Loss:  0.00043257757455908826\n",
            "Inner Loss:  0.00031302076448420327\n",
            "Inner Loss:  0.00022452901716211012\n",
            "Inner Loss:  0.0001924634665816224\n",
            "Inner Loss:  0.00015071219032896415\n",
            "Inner Loss:  0.00012629321489449858\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.23306413177799964\n",
            "Inner Loss:  0.004164137578170214\n",
            "Inner Loss:  0.0008414809625329715\n",
            "Inner Loss:  0.0005017347118285086\n",
            "Inner Loss:  0.0003564827992314739\n",
            "Inner Loss:  0.0002696876825731514\n",
            "Inner Loss:  0.0002289857345333855\n",
            "Inner Loss:  0.00019269574217365256\n",
            "Inner Loss:  0.00015342409876341532\n",
            "Inner Loss:  0.00012834861263399944\n",
            "Step: 15 Test F1: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4355332233410861\n",
            "Inner Loss:  0.011050823809845107\n",
            "Inner Loss:  0.001971122243308595\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.47869193028392537\n",
            "Inner Loss:  0.007685475517064333\n",
            "Inner Loss:  0.0014492680618007267\n",
            "Step: 16 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2340304132750524\n",
            "Inner Loss:  0.005381543422117829\n",
            "Inner Loss:  0.0011309801401304348\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.25646677729673684\n",
            "Inner Loss:  0.005685986817947456\n",
            "Inner Loss:  0.0017027179045336588\n",
            "Step: 17 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3636642250099352\n",
            "Inner Loss:  0.0060891445193971905\n",
            "Inner Loss:  0.0010561514562661095\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.34165444171854426\n",
            "Inner Loss:  0.013526152819395065\n",
            "Inner Loss:  0.00216397042718849\n",
            "Step: 18 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4035976550408772\n",
            "Inner Loss:  0.008997417786823851\n",
            "Inner Loss:  0.002320531921993409\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.38414486444422175\n",
            "Inner Loss:  0.01205585231738431\n",
            "Inner Loss:  0.0013653284737042018\n",
            "Step: 19 \ttraining Acc: 0.85\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.09816480499492693\n",
            "Inner Loss:  0.000856704926783485\n",
            "Inner Loss:  0.0005506985471583903\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.49694045526640757\n",
            "Inner Loss:  0.007632382114284805\n",
            "Inner Loss:  0.0013167792432276265\n",
            "Step: 20 \ttraining Acc: 0.825\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.10613506639908467\n",
            "Inner Loss:  0.000986215558701328\n",
            "Inner Loss:  0.00031346772656044256\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.18510655656323902\n",
            "Inner Loss:  0.0014706382394901343\n",
            "Inner Loss:  0.0005127482623460569\n",
            "Step: 21 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.319537730488394\n",
            "Inner Loss:  0.006226522382348776\n",
            "Inner Loss:  0.0012916171856756722\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.354138189128467\n",
            "Inner Loss:  0.010949683442179645\n",
            "Inner Loss:  0.002241783991589078\n",
            "Step: 22 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.427621883473226\n",
            "Inner Loss:  0.009187430875109774\n",
            "Inner Loss:  0.0017358652881479689\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.19953222965289438\n",
            "Inner Loss:  0.007974836609459348\n",
            "Inner Loss:  0.0010477339133753308\n",
            "Step: 23 \ttraining Acc: 0.75\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.20535721776208707\n",
            "Inner Loss:  0.03543794886874301\n",
            "Inner Loss:  0.0010074275861760335\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.44769843241998125\n",
            "Inner Loss:  0.1023861870967916\n",
            "Inner Loss:  0.03450625303334424\n",
            "Step: 24 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2848701359970229\n",
            "Inner Loss:  0.0028017659372250947\n",
            "Inner Loss:  0.0006862055909420763\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4222910396222557\n",
            "Inner Loss:  0.013746815733611584\n",
            "Inner Loss:  0.0026723165231357726\n",
            "Step: 0 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.19912999249728663\n",
            "Inner Loss:  0.001472477925874825\n",
            "Inner Loss:  0.0004962112663114178\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3742011974266331\n",
            "Inner Loss:  0.009204106671469552\n",
            "Inner Loss:  0.0016038889464523112\n",
            "Step: 1 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.23089677913646614\n",
            "Inner Loss:  0.004133939177596143\n",
            "Inner Loss:  0.001292877905403397\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3157110956464229\n",
            "Inner Loss:  0.011534687198166336\n",
            "Inner Loss:  0.0018482236524245568\n",
            "Step: 2 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2720954851746293\n",
            "Inner Loss:  0.004619773111439177\n",
            "Inner Loss:  0.0006583654446460839\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5861729724066598\n",
            "Inner Loss:  0.04699335553284202\n",
            "Inner Loss:  0.0024630422204998986\n",
            "Step: 3 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3774907636689022\n",
            "Inner Loss:  0.010792343212025506\n",
            "Inner Loss:  0.001452742427188371\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.40016163340104477\n",
            "Inner Loss:  0.006071441208145448\n",
            "Inner Loss:  0.0016483506187796593\n",
            "Step: 4 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.36143361773741034\n",
            "Inner Loss:  0.007284820478941713\n",
            "Inner Loss:  0.00163748547700899\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2580007032624313\n",
            "Inner Loss:  0.003501372877508402\n",
            "Inner Loss:  0.0013615138263308576\n",
            "Step: 5 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.17962901583606644\n",
            "Inner Loss:  0.0022813286299684216\n",
            "Inner Loss:  0.0007816933211870492\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.15444081462088174\n",
            "Inner Loss:  0.0010771912805336928\n",
            "Inner Loss:  0.0005112216666540397\n",
            "Step: 6 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.19672500841885007\n",
            "Inner Loss:  0.0029525205359927247\n",
            "Inner Loss:  0.001089677314407059\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.43984851374157835\n",
            "Inner Loss:  0.005835585528984666\n",
            "Inner Loss:  0.0008989338031304735\n",
            "Step: 7 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.27601873661790577\n",
            "Inner Loss:  0.004316301683762244\n",
            "Inner Loss:  0.0007372960847403322\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2836860104330948\n",
            "Inner Loss:  0.003240119931953294\n",
            "Inner Loss:  0.0008389052735375506\n",
            "Step: 8 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2887198595064027\n",
            "Inner Loss:  0.004208115129066365\n",
            "Inner Loss:  0.0012781618861481547\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5113987803592214\n",
            "Inner Loss:  0.008233885081218821\n",
            "Inner Loss:  0.0009245591188248779\n",
            "Step: 9 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2572242563889761\n",
            "Inner Loss:  0.008478026304926192\n",
            "Inner Loss:  0.0017861129183854376\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.32970712014607023\n",
            "Inner Loss:  0.006865105591714382\n",
            "Inner Loss:  0.0017756748711690307\n",
            "Step: 10 \ttraining Acc: 0.8\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.28243575077171307\n",
            "Inner Loss:  0.0035308440149362597\n",
            "Inner Loss:  0.0011039676111457603\n",
            "Inner Loss:  0.0005687134232305523\n",
            "Inner Loss:  0.0003993868678142982\n",
            "Inner Loss:  0.0003014555342295872\n",
            "Inner Loss:  0.00022500303748529404\n",
            "Inner Loss:  0.00019007673628428684\n",
            "Inner Loss:  0.0001544289885454678\n",
            "Inner Loss:  0.00013278665677976927\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.26147103535809685\n",
            "Inner Loss:  0.0017278752805265998\n",
            "Inner Loss:  0.00043176633854662735\n",
            "Inner Loss:  0.0002758432030012565\n",
            "Inner Loss:  0.00023307200171984732\n",
            "Inner Loss:  0.00019776627803886577\n",
            "Inner Loss:  0.0001534317125333473\n",
            "Inner Loss:  0.00014156946937354014\n",
            "Inner Loss:  0.0001181731911076765\n",
            "Inner Loss:  0.00010803832057198244\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2766184497824205\n",
            "Inner Loss:  0.006524806110454457\n",
            "Inner Loss:  0.0014248985264982497\n",
            "Inner Loss:  0.0007604280170718474\n",
            "Inner Loss:  0.0004919578038555171\n",
            "Inner Loss:  0.0003026519053881722\n",
            "Inner Loss:  0.00022665662150497416\n",
            "Inner Loss:  0.00018258299886448576\n",
            "Inner Loss:  0.00014289004216802174\n",
            "Inner Loss:  0.000122271738031746\n",
            "Step: 10 Test F1: 0.9666666666666667\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.25812236744345035\n",
            "Inner Loss:  0.0026582798787525724\n",
            "Inner Loss:  0.000548411622211071\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1894832704814949\n",
            "Inner Loss:  0.0015911647600920073\n",
            "Inner Loss:  0.037372420117857734\n",
            "Step: 11 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1572966721141711\n",
            "Inner Loss:  0.011644167958625726\n",
            "Inner Loss:  0.0012631934036367706\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16374848556837865\n",
            "Inner Loss:  0.0015326564566099218\n",
            "Inner Loss:  0.0005325459143412965\n",
            "Step: 12 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3089435137808323\n",
            "Inner Loss:  0.0026300180636878523\n",
            "Inner Loss:  0.0009098974156326481\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.22540601565768675\n",
            "Inner Loss:  0.03001192523100014\n",
            "Inner Loss:  0.0009922196456630314\n",
            "Step: 13 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.39778322013860035\n",
            "Inner Loss:  0.00767201730715377\n",
            "Inner Loss:  0.00149955357691007\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.13464522993724262\n",
            "Inner Loss:  0.0020653793222403954\n",
            "Inner Loss:  0.0004717238230763802\n",
            "Step: 14 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.02193960325426555\n",
            "Inner Loss:  0.00998870017065201\n",
            "Inner Loss:  0.0005456156546383031\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3368893853787865\n",
            "Inner Loss:  0.0023957493914557354\n",
            "Inner Loss:  0.00045844098453276923\n",
            "Step: 15 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.20924405583978764\n",
            "Inner Loss:  0.0027305094990879297\n",
            "Inner Loss:  0.0007895702479540237\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2237612368439191\n",
            "Inner Loss:  0.004013772471807897\n",
            "Inner Loss:  0.000708258877109204\n",
            "Step: 16 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2682826765147703\n",
            "Inner Loss:  0.0037578658666461706\n",
            "Inner Loss:  0.0010987745481543243\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.13136112985999457\n",
            "Inner Loss:  0.0016880685995732034\n",
            "Inner Loss:  0.0005042779417375901\n",
            "Step: 17 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3818837771458285\n",
            "Inner Loss:  0.004223504901996681\n",
            "Inner Loss:  0.0008055433198543531\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.33139844770942417\n",
            "Inner Loss:  0.0028730142262897323\n",
            "Inner Loss:  0.0006836016795464925\n",
            "Step: 18 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2756463471533997\n",
            "Inner Loss:  0.0036817342708153383\n",
            "Inner Loss:  0.0010821757106376545\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.21747571768771326\n",
            "Inner Loss:  0.0025505780026183595\n",
            "Inner Loss:  0.0005467779701575637\n",
            "Step: 19 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2215746351783829\n",
            "Inner Loss:  0.004337994398416153\n",
            "Inner Loss:  0.003126279334537685\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.34923989937773775\n",
            "Inner Loss:  0.0041435338955904755\n",
            "Inner Loss:  0.0007514601789547928\n",
            "Step: 20 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.38737994158041794\n",
            "Inner Loss:  0.010960836628718036\n",
            "Inner Loss:  0.0028121722529509236\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.04613884744217752\n",
            "Inner Loss:  0.00018803655361157974\n",
            "Inner Loss:  0.008923614094133623\n",
            "Step: 21 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.18144421680231712\n",
            "Inner Loss:  0.024211587650435313\n",
            "Inner Loss:  0.0011763902896616077\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.29612734807389124\n",
            "Inner Loss:  0.004882283974438906\n",
            "Inner Loss:  0.0009444382324415658\n",
            "Step: 22 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.27299236599355936\n",
            "Inner Loss:  0.003000952153732734\n",
            "Inner Loss:  0.0006636787688226572\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.37884922158471973\n",
            "Inner Loss:  0.007337523624300957\n",
            "Inner Loss:  0.0016802877819697773\n",
            "Step: 23 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.28829010522791315\n",
            "Inner Loss:  0.0019744967077193515\n",
            "Inner Loss:  0.0002860228664108685\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2534759838100789\n",
            "Inner Loss:  0.002216399073534246\n",
            "Inner Loss:  0.0003764437195578856\n",
            "Step: 24 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3148153807435717\n",
            "Inner Loss:  0.07188323100230523\n",
            "Inner Loss:  0.012788869041417326\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.18459291011095047\n",
            "Inner Loss:  0.0012897567399444857\n",
            "Inner Loss:  0.00030846109439153224\n",
            "Step: 0 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3310263814928476\n",
            "Inner Loss:  0.05231339504410114\n",
            "Inner Loss:  0.003759167722559401\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4768941044541342\n",
            "Inner Loss:  0.008279200310685806\n",
            "Inner Loss:  0.0025738507309662445\n",
            "Step: 1 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.20887203085502343\n",
            "Inner Loss:  0.001998371378119503\n",
            "Inner Loss:  0.0006967902383101838\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.20438954274037055\n",
            "Inner Loss:  0.0036243614740669727\n",
            "Inner Loss:  0.0003713022202386388\n",
            "Step: 2 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.42360321685139624\n",
            "Inner Loss:  0.006682582332619599\n",
            "Inner Loss:  0.001697610880780433\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.675354081605162\n",
            "Inner Loss:  0.015186154682721411\n",
            "Inner Loss:  0.003543884925810354\n",
            "Step: 3 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.6995220258831978\n",
            "Inner Loss:  0.013962677147771631\n",
            "Inner Loss:  0.003092313517949411\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.15615319294322813\n",
            "Inner Loss:  0.0017160465940833092\n",
            "Inner Loss:  0.00042139269394933114\n",
            "Step: 4 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4994938384874591\n",
            "Inner Loss:  0.11516264799450125\n",
            "Inner Loss:  0.022635858173349073\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.5047709738303509\n",
            "Inner Loss:  0.014944286883941718\n",
            "Inner Loss:  0.002101400418074003\n",
            "Step: 5 \ttraining Acc: 0.85\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2749871279977794\n",
            "Inner Loss:  0.0033018423543710795\n",
            "Inner Loss:  0.0011428832575412734\n",
            "Inner Loss:  0.0006310158891470305\n",
            "Inner Loss:  0.00044577167344479155\n",
            "Inner Loss:  0.00030853236759347577\n",
            "Inner Loss:  0.00021863234204439714\n",
            "Inner Loss:  0.00018188702441485866\n",
            "Inner Loss:  0.00015084157036783705\n",
            "Inner Loss:  0.0001310377421240056\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.18909054515617235\n",
            "Inner Loss:  0.0010372648913679378\n",
            "Inner Loss:  0.00027683524863927493\n",
            "Inner Loss:  0.00017786864191293716\n",
            "Inner Loss:  0.00015083889489428008\n",
            "Inner Loss:  0.00011815846976657798\n",
            "Inner Loss:  9.35934336406977e-05\n",
            "Inner Loss:  8.789733900422496e-05\n",
            "Inner Loss:  7.026628736639395e-05\n",
            "Inner Loss:  6.288872879979732e-05\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.18509410119232989\n",
            "Inner Loss:  0.002249849561069693\n",
            "Inner Loss:  0.0003773125063162297\n",
            "Inner Loss:  0.0002445143410503598\n",
            "Inner Loss:  0.00018064428669666604\n",
            "Inner Loss:  0.0001462056316086091\n",
            "Inner Loss:  0.0001319558422047911\n",
            "Inner Loss:  0.00010688109198651676\n",
            "Inner Loss:  8.67321775461148e-05\n",
            "Inner Loss:  7.345100831506508e-05\n",
            "Step: 5 Test F1: 0.9499999999999998\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1892694564802306\n",
            "Inner Loss:  0.0015327258068802102\n",
            "Inner Loss:  0.00038357147630969327\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2531223929254338\n",
            "Inner Loss:  0.006390969834423491\n",
            "Inner Loss:  0.0007546650220839572\n",
            "Step: 6 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2969532307636525\n",
            "Inner Loss:  0.003018859906920365\n",
            "Inner Loss:  0.001044960118763681\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.26509907921510084\n",
            "Inner Loss:  0.0015734518778377346\n",
            "Inner Loss:  0.00030046548012511006\n",
            "Step: 7 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.20230755988242372\n",
            "Inner Loss:  0.0024721357372722457\n",
            "Inner Loss:  0.0006675991462543607\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.32802069446604165\n",
            "Inner Loss:  0.004178976307490042\n",
            "Inner Loss:  0.0008049247054649251\n",
            "Step: 8 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.40263817672218594\n",
            "Inner Loss:  0.004575078009760806\n",
            "Inner Loss:  0.0013455704153914536\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.13958090979057097\n",
            "Inner Loss:  0.0013486452683407282\n",
            "Inner Loss:  0.0006618276695787374\n",
            "Step: 9 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.11288152689979013\n",
            "Inner Loss:  0.00043194916049417643\n",
            "Inner Loss:  0.0001681543716196237\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.45559922313051565\n",
            "Inner Loss:  0.0050828643475792235\n",
            "Inner Loss:  0.0007596999972260424\n",
            "Step: 10 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2954509338430528\n",
            "Inner Loss:  0.0035070128007126705\n",
            "Inner Loss:  0.000710355317486184\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.11843042090601687\n",
            "Inner Loss:  0.0008848339369121407\n",
            "Inner Loss:  0.00019234219507779926\n",
            "Step: 11 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.25215511038965943\n",
            "Inner Loss:  0.0025750919594429433\n",
            "Inner Loss:  0.0005922167537002159\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.1961037304884355\n",
            "Inner Loss:  0.0022325064720852034\n",
            "Inner Loss:  0.00031488076534255275\n",
            "Step: 12 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24651834022785937\n",
            "Inner Loss:  0.0008628847800926971\n",
            "Inner Loss:  0.0003509419995160507\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.38758909585885704\n",
            "Inner Loss:  0.0018405154779819505\n",
            "Inner Loss:  0.00043536092354250807\n",
            "Step: 13 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2660985084117523\n",
            "Inner Loss:  0.004367204449538674\n",
            "Inner Loss:  0.0009667790478228458\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2555605447185891\n",
            "Inner Loss:  0.00267500667333869\n",
            "Inner Loss:  0.00040977384612363366\n",
            "Step: 14 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1626646022445389\n",
            "Inner Loss:  0.003719097834878734\n",
            "Inner Loss:  0.0004220908532650875\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16624303258556342\n",
            "Inner Loss:  0.0016329681467530982\n",
            "Inner Loss:  0.0004101694586487221\n",
            "Step: 15 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.13919495295600168\n",
            "Inner Loss:  0.0015538820797311409\n",
            "Inner Loss:  0.0004376638514388885\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.17287353805399366\n",
            "Inner Loss:  0.00036239142562927943\n",
            "Inner Loss:  0.00017913044679776898\n",
            "Step: 16 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.19816585468860076\n",
            "Inner Loss:  0.003089190261172397\n",
            "Inner Loss:  0.0005429290343142514\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.31185522050197634\n",
            "Inner Loss:  0.0021541591766955598\n",
            "Inner Loss:  0.0010314977511630527\n",
            "Step: 17 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.281223194008427\n",
            "Inner Loss:  0.003286240988277963\n",
            "Inner Loss:  0.00046551729402770955\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.19513474796882033\n",
            "Inner Loss:  0.0019334451561527593\n",
            "Inner Loss:  0.00034835044061765075\n",
            "Step: 18 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3756043389439583\n",
            "Inner Loss:  0.006071815766128046\n",
            "Inner Loss:  0.0011170274561404117\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2832724930984633\n",
            "Inner Loss:  0.003960311978257128\n",
            "Inner Loss:  0.0007381064601109496\n",
            "Step: 19 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.26917727664113045\n",
            "Inner Loss:  0.0020138278736599852\n",
            "Inner Loss:  0.0004116783384233713\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.04541929280302221\n",
            "Inner Loss:  0.00025758663209022155\n",
            "Inner Loss:  9.713649862013491e-05\n",
            "Step: 20 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.17134981246532074\n",
            "Inner Loss:  0.002001751397204186\n",
            "Inner Loss:  0.000576948347900595\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16599667917138763\n",
            "Inner Loss:  0.0023367800334069344\n",
            "Inner Loss:  0.0009563154474432979\n",
            "Step: 21 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.20704977786434547\n",
            "Inner Loss:  0.002034803802546646\n",
            "Inner Loss:  0.000628984283788928\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.11443561388711844\n",
            "Inner Loss:  0.0009950713262826736\n",
            "Inner Loss:  0.00018905628530774266\n",
            "Step: 22 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1702341072294595\n",
            "Inner Loss:  0.005959717166011355\n",
            "Inner Loss:  0.0005680159000413758\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.325899882907314\n",
            "Inner Loss:  0.005506295344925353\n",
            "Inner Loss:  0.0005289103553098227\n",
            "Step: 23 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.29856504686176777\n",
            "Inner Loss:  0.0028238115732425024\n",
            "Inner Loss:  0.0005592841480392963\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4093329678954823\n",
            "Inner Loss:  0.00847837541784559\n",
            "Inner Loss:  0.0011192069921110357\n",
            "Step: 24 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3481472378397094\n",
            "Inner Loss:  0.005094508008499231\n",
            "Inner Loss:  0.000953672595122563\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.23435592024387525\n",
            "Inner Loss:  0.005547121133921402\n",
            "Inner Loss:  0.0017032895536561096\n",
            "Step: 0 \ttraining Acc: 0.95\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3181801680724935\n",
            "Inner Loss:  0.03440894765247192\n",
            "Inner Loss:  0.0025418230631787863\n",
            "Inner Loss:  0.0011462299236362533\n",
            "Inner Loss:  0.0007007543089067829\n",
            "Inner Loss:  0.0005191431513854436\n",
            "Inner Loss:  0.0003821747751706945\n",
            "Inner Loss:  0.0003338115244072729\n",
            "Inner Loss:  0.000255565599737955\n",
            "Inner Loss:  0.0002341496043040284\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.16453108131619437\n",
            "Inner Loss:  0.0026932066414571765\n",
            "Inner Loss:  0.0003882416598831436\n",
            "Inner Loss:  0.00021026117610745132\n",
            "Inner Loss:  0.00016351339997657175\n",
            "Inner Loss:  0.00017509314368778308\n",
            "Inner Loss:  9.962785614853991e-05\n",
            "Inner Loss:  9.085492950232168e-05\n",
            "Inner Loss:  7.64383637163389e-05\n",
            "Inner Loss:  7.028944206207857e-05\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1854962240322493\n",
            "Inner Loss:  0.0009225343320784825\n",
            "Inner Loss:  0.0003252167745293783\n",
            "Inner Loss:  0.0002414770029385441\n",
            "Inner Loss:  0.00018623523646965623\n",
            "Inner Loss:  0.00016606222093936855\n",
            "Inner Loss:  0.00013700805097219666\n",
            "Inner Loss:  0.00011483183334348723\n",
            "Inner Loss:  9.375637039608722e-05\n",
            "Inner Loss:  7.779103387812418e-05\n",
            "Step: 0 Test F1: 0.9499999999999998\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.231714146444574\n",
            "Inner Loss:  0.006488587407927428\n",
            "Inner Loss:  0.0004634457207950098\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.0826846995977186\n",
            "Inner Loss:  0.0006328258095891215\n",
            "Inner Loss:  0.00013702987884503922\n",
            "Step: 1 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5065295987629465\n",
            "Inner Loss:  0.012178966775536537\n",
            "Inner Loss:  0.0014188748651317187\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.26280550426703747\n",
            "Inner Loss:  0.0033363028362925562\n",
            "Inner Loss:  0.0004266227603823479\n",
            "Step: 2 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.13325790907921536\n",
            "Inner Loss:  0.005347983944895012\n",
            "Inner Loss:  0.0005633772733355207\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.37543561682105064\n",
            "Inner Loss:  0.0035160646407998036\n",
            "Inner Loss:  0.0013861442650003092\n",
            "Step: 3 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.2524386959350003\n",
            "Inner Loss:  0.00126159140407773\n",
            "Inner Loss:  0.00027511191105337014\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.30005470832942854\n",
            "Inner Loss:  0.042346619601760595\n",
            "Inner Loss:  0.004417076174701963\n",
            "Step: 4 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.18978716715771174\n",
            "Inner Loss:  0.0005861062257151518\n",
            "Inner Loss:  0.00023617197127480592\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.27037858823730077\n",
            "Inner Loss:  0.0011554431153594383\n",
            "Inner Loss:  0.0005358157671123211\n",
            "Step: 5 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1746905638220986\n",
            "Inner Loss:  0.000742376985726878\n",
            "Inner Loss:  0.00024299961556347886\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.30322399210750256\n",
            "Inner Loss:  0.003919650600957019\n",
            "Inner Loss:  0.0011423965583422355\n",
            "Step: 6 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.032680923011087416\n",
            "Inner Loss:  0.000134668339991809\n",
            "Inner Loss:  9.29128379669107e-05\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.13278048688412777\n",
            "Inner Loss:  0.027309513867034445\n",
            "Inner Loss:  0.0003764349302010877\n",
            "Step: 7 \ttraining Acc: 0.8999999999999999\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3321146276347073\n",
            "Inner Loss:  0.006180983402633241\n",
            "Inner Loss:  0.001205339129748089\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.22237541247159243\n",
            "Inner Loss:  0.002055605224865888\n",
            "Inner Loss:  0.0003603112293473844\n",
            "Step: 8 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4028577418149715\n",
            "Inner Loss:  0.15512108270611083\n",
            "Inner Loss:  0.011746344322870885\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.18127760869850004\n",
            "Inner Loss:  0.0009682666651705014\n",
            "Inner Loss:  0.00025125048289607676\n",
            "Step: 9 \ttraining Acc: 0.875\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.009999436534209443\n",
            "Inner Loss:  5.99041793196063e-05\n",
            "Inner Loss:  3.186792361832756e-05\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3068087002528565\n",
            "Inner Loss:  0.0031006659181522472\n",
            "Inner Loss:  0.0011116679026080029\n",
            "Step: 10 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24998826174331562\n",
            "Inner Loss:  0.020265647742365087\n",
            "Inner Loss:  0.002487342305747526\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.31506797218961374\n",
            "Inner Loss:  0.001327569837615426\n",
            "Inner Loss:  0.00037611023539544215\n",
            "Step: 11 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.004739878948644868\n",
            "Inner Loss:  0.00010755216810918813\n",
            "Inner Loss:  6.858006599941291e-05\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.22853657694733037\n",
            "Inner Loss:  0.0015659011717486595\n",
            "Inner Loss:  0.0005945692786813847\n",
            "Step: 12 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.1397294008742652\n",
            "Inner Loss:  0.011261801721827527\n",
            "Inner Loss:  0.0004654735572070682\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16501020466343366\n",
            "Inner Loss:  0.01915637171727472\n",
            "Inner Loss:  0.00035238321288488805\n",
            "Step: 13 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3418873655110864\n",
            "Inner Loss:  0.0032792627212724517\n",
            "Inner Loss:  0.0007366751212560173\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.3903945103021605\n",
            "Inner Loss:  0.00651105197279581\n",
            "Inner Loss:  0.0012074332833955331\n",
            "Step: 14 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.5978967398405075\n",
            "Inner Loss:  0.008431498094328813\n",
            "Inner Loss:  0.0013060325873084366\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.08553773806696492\n",
            "Inner Loss:  0.0003329114738984832\n",
            "Inner Loss:  0.0001388782007519954\n",
            "Step: 15 \ttraining Acc: 0.9\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.24405863102791564\n",
            "Inner Loss:  0.002490878171686615\n",
            "Inner Loss:  0.0003961451501319451\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.17744520168551908\n",
            "Inner Loss:  0.001641015089782221\n",
            "Inner Loss:  0.0005760073462235076\n",
            "Step: 16 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.06791430933351096\n",
            "Inner Loss:  0.07724224187300674\n",
            "Inner Loss:  0.0005669893954680967\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.21657694144440548\n",
            "Inner Loss:  0.011931520953242267\n",
            "Inner Loss:  0.000593299578343119\n",
            "Step: 17 \ttraining Acc: 0.95\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.42699081051562515\n",
            "Inner Loss:  0.013053905884070056\n",
            "Inner Loss:  0.0015165071235969663\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.27662439311721493\n",
            "Inner Loss:  0.0027102846652269363\n",
            "Inner Loss:  0.0004599949627715562\n",
            "Step: 18 \ttraining Acc: 0.975\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.14979028923594992\n",
            "Inner Loss:  0.0007129281792523605\n",
            "Inner Loss:  0.0003447176921846611\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.26932846076254335\n",
            "Inner Loss:  0.0024993675594617215\n",
            "Inner Loss:  0.0005752492829092912\n",
            "Step: 19 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.11697004665620625\n",
            "Inner Loss:  0.004265186364396608\n",
            "Inner Loss:  0.00032495275289485496\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.21957026029537832\n",
            "Inner Loss:  0.0027861012910891858\n",
            "Inner Loss:  0.00036057216805472436\n",
            "Step: 20 \ttraining Acc: 0.925\n",
            "\n",
            "-----------------Testing Mode-----------------\n",
            "\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.29947509420370416\n",
            "Inner Loss:  0.0033174769154616763\n",
            "Inner Loss:  0.0007249880914709397\n",
            "Inner Loss:  0.00035835640613056185\n",
            "Inner Loss:  0.0002977151619104136\n",
            "Inner Loss:  0.0002548870667981516\n",
            "Inner Loss:  0.00019720147455310716\n",
            "Inner Loss:  0.00017892629382134016\n",
            "Inner Loss:  0.00014951471322482185\n",
            "Inner Loss:  0.00013006079409803663\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.3083018876080002\n",
            "Inner Loss:  0.0027017848333343863\n",
            "Inner Loss:  0.0005042721625483994\n",
            "Inner Loss:  0.00026801978154773157\n",
            "Inner Loss:  0.00019572608705077852\n",
            "Inner Loss:  0.0001724971059177603\n",
            "Inner Loss:  0.0001318238116385016\n",
            "Inner Loss:  0.00011457184466832717\n",
            "Inner Loss:  9.82901723805948e-05\n",
            "Inner Loss:  8.579558302049659e-05\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.22449097528754333\n",
            "Inner Loss:  0.0025866090852235046\n",
            "Inner Loss:  0.00040176898307566134\n",
            "Inner Loss:  0.00023793094754052748\n",
            "Inner Loss:  0.00015516149765712077\n",
            "Inner Loss:  0.00015543934361111105\n",
            "Inner Loss:  0.00011596388711560783\n",
            "Inner Loss:  9.666069568733551e-05\n",
            "Inner Loss:  7.435169702927981e-05\n",
            "Inner Loss:  6.473496094778446e-05\n",
            "Step: 20 Test F1: 0.9666666666666667\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.10542214121336915\n",
            "Inner Loss:  0.0005932027498991894\n",
            "Inner Loss:  0.00015876570978434756\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.2323097231689774\n",
            "Inner Loss:  0.0067258501159293315\n",
            "Inner Loss:  0.0017871117452159524\n",
            "Step: 21 \ttraining Acc: 0.925\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.35111908957021243\n",
            "Inner Loss:  0.005730686775807824\n",
            "Inner Loss:  0.0007559056892724973\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.4095400383230299\n",
            "Inner Loss:  0.003275138043266322\n",
            "Inner Loss:  0.0005891342298127711\n",
            "Step: 22 \ttraining Acc: 1.0\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.4349371675801064\n",
            "Inner Loss:  0.010393137910536357\n",
            "Inner Loss:  0.0016707792778366379\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.14681729640246236\n",
            "Inner Loss:  0.0006275975132926501\n",
            "Inner Loss:  0.00020027316350024194\n",
            "Step: 23 \ttraining Acc: 0.8500000000000001\n",
            "----Task 0 ----\n",
            "Inner Loss:  0.07748492566003863\n",
            "Inner Loss:  0.0004813753371958488\n",
            "Inner Loss:  0.0001450131946642484\n",
            "----Task 1 ----\n",
            "Inner Loss:  0.16164889951635683\n",
            "Inner Loss:  0.0005593909466240023\n",
            "Inner Loss:  0.00033580563363752196\n",
            "Step: 24 \ttraining Acc: 0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHzw99Mz9OYq"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}